{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import cv2 as cv\n",
    "import pywt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"Aditya\",\"Rahul\",\"Sangeeta\",\"Sunil\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_dirs = ['FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya','FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul','FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta','FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aditya': ['FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya10.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya11.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya12.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya2.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya28.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya3.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya31.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya32.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya33.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya34.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya37.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya38.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya4.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya7.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Aditya\\\\Aditya9.png'], 'Rahul': ['FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul1.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul10.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul18.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul19.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul2.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul20.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul22.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul24.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul25.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul26.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul3.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul35.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul36.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul6.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul7.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul8.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Rahul\\\\Rahul9.png'], 'Sangeeta': ['FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta14.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta22.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta28.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta29.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta3.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta31.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta32.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta36.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta5.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta8.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sangeeta9.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sunil16.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sunil18.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sangeeta\\\\Sunil2.png'], 'Sunil': ['FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil10.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil14.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil15.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil17.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil19.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil20.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil21.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil22.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil23.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil25.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil26.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil27.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil28.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil29.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil38.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil39.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil4.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil5.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil7.png', 'FACE RECOGNITION AND IDENTIFICATION/model/Family Dataset/cropped/Sunil\\\\Sunil9.png']}\n"
     ]
    }
   ],
   "source": [
    "member_file_dict = {}\n",
    "for img_dirs in cropped_image_dirs:\n",
    "    member_name = img_dirs.split(\"/\")[-1]\n",
    "    file_list = []\n",
    "    for image_files in os.scandir(img_dirs):\n",
    "        file_list.append(image_files.path)\n",
    "    member_file_dict[member_name] = file_list\n",
    "print(member_file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aditya': 0, 'Rahul': 1, 'Sangeeta': 2, 'Sunil': 3}\n"
     ]
    }
   ],
   "source": [
    "member_names = {}\n",
    "count = 0\n",
    "for member_name in member_file_dict.keys():\n",
    "    member_names[member_name] = count\n",
    "    count = count+1\n",
    "print(member_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def wavelet_transform(img,mode=\"haar\",level=1):\n",
    "    img_array = img\n",
    "    img_array = cv.cvtColor(img_array,cv.COLOR_BGR2GRAY)\n",
    "    img_array = np.float32(img_array)\n",
    "    img_array /= 255;\n",
    "    coeffs=pywt.wavedec2(img_array, mode, level=level)\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for member,training_files in member_file_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv.imread(training_image)\n",
    "        scalled_image = cv.resize(img,(32,32))\n",
    "        image_wav_transform = wavelet_transform(scalled_image,'db1',5)\n",
    "        transformed_scalled = cv.resize(image_wav_transform,(32,32))\n",
    "        image_vertically_stacked = np.vstack((scalled_image.reshape(32*32*3,1),transformed_scalled.reshape(32*32,1)))\n",
    "        X.append(image_vertically_stacked)\n",
    "        y.append(member_names[member]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 52]\n",
      " [ 76]\n",
      " [156]\n",
      " ...\n",
      " [189]\n",
      " [193]\n",
      " [192]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 4096)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 4096), (17, 4096))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('scaler',StandardScaler()),('svc',SVC(kernel = 'linear', C=10))])\n",
    "pipe.fit(X_train,y_train)\n",
    "pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "           2       1.00      0.80      0.89         5\n",
      "           3       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.94        17\n",
      "   macro avg       0.96      0.95      0.95        17\n",
      "weighted avg       0.95      0.94      0.94        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear','poly','sigmoid']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>{'logisticregression__C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.815556   \n",
       "1        random_forest    0.611111   \n",
       "2  logistic_regression    0.797778   \n",
       "\n",
       "                                    best_params  \n",
       "0        {'svc__C': 1, 'svc__kernel': 'linear'}  \n",
       "1  {'randomforestclassifier__n_estimators': 10}  \n",
       "2                  {'logisticregression__C': 1}  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['svm'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6470588235294118"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['random_forest'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['logistic_regression'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = best_estimators['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 0, 0],\n",
       "       [0, 3, 0, 0],\n",
       "       [0, 0, 4, 1],\n",
       "       [0, 0, 0, 6]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, best_clf.predict(X_test))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Face_recognition_model.pickle\",\"wb\") as f:\n",
    "    pickle.dump(best_clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"member_numbers.json\",\"w\") as f:\n",
    "    f.write(json.dumps(member_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
